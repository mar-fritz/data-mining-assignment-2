{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Εργασία 2 (Τεχνικές Εξόρυξης Δεδομένων)\n",
    "## Data Mining: Assignment 2\n",
    "***\n",
    "### Μαρία Φριτζελά 1115201400218\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import csv\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "from IPython.core.display import display\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn import  svm, metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Κατηγοριοποίηση δεδομένων κειμένου από ειδησιογραφικά άρθρα 5 κατηγοριών:</br>\n",
    "Classifying text data from articles of 5 different categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "categories = ['business', 'entertainment', 'politics', 'sport', 'tech']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Get names of files for testing and training\n",
    "Data set consists of 2225 documents from a news website\n",
    "corresponding to stories in five topical areas from 2004-2005.</br>\n",
    "</br>\n",
    "80% of data points (files) will be used for training, the remaining 20% will be used for testing.</br>\n",
    "We will be collecting the files names as elements in two lists (one for each purpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "files_path = 'fulltext/data/'\n",
    "train_files = []    # list of files names that will be used for training\n",
    "test_files = []     # list of files names that will be used for testing\n",
    "\n",
    "for category in categories:\n",
    "    # get all txt files names from current category\n",
    "    files = glob.glob(files_path+category+'/*.txt')\n",
    "    # sort them alphabetically\n",
    "    files.sort()\n",
    "    # separate list so that first 80% will be copied into the train_files list\n",
    "    sep_index = round(len(files) * 0.8)\n",
    "    train_files.extend(files[:sep_index])\n",
    "    test_files.extend(files[sep_index:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Total files: 2225\")\n",
    "print(\"# of train files: \"+str(len(train_files)))\n",
    "print(\"# of test files: \"+str(len(test_files)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Create file train_set.tsv\n",
    "Columns: id, title, content, category <br>\n",
    "_The id is the name of the text file with the first letter of the category prepended (ex. \"b001\")_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('train_set.tsv', 'wt') as out_file:\n",
    "    tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "    # write header row\n",
    "    tsv_writer.writerow(['id', 'title', 'content', 'category'])\n",
    "    # write rows for all other files\n",
    "    for file_path in train_files:\n",
    "        with open(file_path) as f:\n",
    "            # read all lines of file split them in a list removing '\\n'\n",
    "            # iterate through elements in list removing empty ones (empty strings are False)\n",
    "            try:\n",
    "                content = [line for line in f.read().splitlines() if line.strip()]\n",
    "                # unpack the information we need from the file path\n",
    "                _, _, cat, name, _ = file_path.replace('.', '/').split('/')\n",
    "                # Write row\n",
    "                tsv_writer.writerow([cat[0]+name,\n",
    "                                 content.pop(0),\n",
    "                                 \" \".join(content),\n",
    "                                 cat])\n",
    "            except UnicodeDecodeError:\n",
    "                print(\"UnicodeDecodeError for file: \"+file_path+\". File skipped\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Create file test_set.tsv\n",
    "Columns: id, title, content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('test_set.tsv', 'wt') as out_file:\n",
    "    tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "    # write header row\n",
    "    tsv_writer.writerow(['id', 'title', 'content'])\n",
    "    # write rows for all other files\n",
    "    for file_path in test_files:\n",
    "        with open(file_path) as f:\n",
    "            # read all lines of file split them in a list removing '\\n'\n",
    "            # iterate through elements in list removing empty ones (empty strings are False)\n",
    "            try:\n",
    "                content = [line for line in f.read().splitlines() if line.strip()]\n",
    "                # unpack the information we need from the file path\n",
    "                _, _, cat, name, _ = file_path.replace('.', '/').split('/')\n",
    "                # Write row\n",
    "                tsv_writer.writerow([cat[0]+name,\n",
    "                                 content.pop(0),\n",
    "                                 \" \".join(content)])\n",
    "            except UnicodeDecodeError:\n",
    "                print(\"UnicodeDecodeError for file: \"+file_path+\". File skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Create a file with the full dataset: dataset.tsv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnicodeDecodeError for file: fulltext/data/sport/199.txt. File skipped\n"
     ]
    }
   ],
   "source": [
    "with open('dataset.tsv', 'wt') as out_file:\n",
    "    tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "    # write header row\n",
    "    tsv_writer.writerow(['id', 'title', 'content', 'category'])\n",
    "    # write rows for all other files\n",
    "    for file_path in chain(train_files, test_files):\n",
    "        with open(file_path) as f:\n",
    "            # read all lines of file split them in a list removing '\\n'\n",
    "            # iterate through elements in list removing empty ones (empty strings are False)\n",
    "            try:\n",
    "                content = [line for line in f.read().splitlines() if line.strip()]\n",
    "                # unpack the information we need from the file path\n",
    "                _, _, cat, name, _ = file_path.replace('.', '/').split('/')\n",
    "                # Write row\n",
    "                tsv_writer.writerow([cat[0]+name,\n",
    "                                 content.pop(0),\n",
    "                                 \" \".join(content),\n",
    "                                 cat])\n",
    "            except UnicodeDecodeError:\n",
    "                print(\"UnicodeDecodeError for file: \"+file_path+\". File skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Create a DataFrame for the data_set (id column as the index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b001</th>\n",
       "      <td>Ad sales boost Time Warner profit</td>\n",
       "      <td>Quarterly profits at US media giant TimeWarner...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b002</th>\n",
       "      <td>Dollar gains on Greenspan speech</td>\n",
       "      <td>The dollar has hit its highest level against t...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b003</th>\n",
       "      <td>Yukos unit buyer faces loan claim</td>\n",
       "      <td>The owners of embattled Russian oil giant Yuko...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b004</th>\n",
       "      <td>High fuel prices hit BA's profits</td>\n",
       "      <td>British Airways has blamed high fuel prices fo...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b005</th>\n",
       "      <td>Pernod takeover talk lifts Domecq</td>\n",
       "      <td>Shares in UK drinks and food firm Allied Domec...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t397</th>\n",
       "      <td>BT program to beat dialler scams</td>\n",
       "      <td>BT is introducing two initiatives to help beat...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t398</th>\n",
       "      <td>Spam e-mails tempt net shoppers</td>\n",
       "      <td>Computer users across the world continue to ig...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t399</th>\n",
       "      <td>Be careful how you code</td>\n",
       "      <td>A new European directive could put software wr...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t400</th>\n",
       "      <td>US cyber security chief resigns</td>\n",
       "      <td>The man making sure US computer networks are s...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t401</th>\n",
       "      <td>Losing yourself in online gaming</td>\n",
       "      <td>Online role playing games are time-consuming, ...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2224 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  title  \\\n",
       "id                                        \n",
       "b001  Ad sales boost Time Warner profit   \n",
       "b002   Dollar gains on Greenspan speech   \n",
       "b003  Yukos unit buyer faces loan claim   \n",
       "b004  High fuel prices hit BA's profits   \n",
       "b005  Pernod takeover talk lifts Domecq   \n",
       "...                                 ...   \n",
       "t397   BT program to beat dialler scams   \n",
       "t398    Spam e-mails tempt net shoppers   \n",
       "t399            Be careful how you code   \n",
       "t400    US cyber security chief resigns   \n",
       "t401   Losing yourself in online gaming   \n",
       "\n",
       "                                                content  category  \n",
       "id                                                                 \n",
       "b001  Quarterly profits at US media giant TimeWarner...  business  \n",
       "b002  The dollar has hit its highest level against t...  business  \n",
       "b003  The owners of embattled Russian oil giant Yuko...  business  \n",
       "b004  British Airways has blamed high fuel prices fo...  business  \n",
       "b005  Shares in UK drinks and food firm Allied Domec...  business  \n",
       "...                                                 ...       ...  \n",
       "t397  BT is introducing two initiatives to help beat...      tech  \n",
       "t398  Computer users across the world continue to ig...      tech  \n",
       "t399  A new European directive could put software wr...      tech  \n",
       "t400  The man making sure US computer networks are s...      tech  \n",
       "t401  Online role playing games are time-consuming, ...      tech  \n",
       "\n",
       "[2224 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testdf = pd.read_csv(\"test_set.tsv\", sep='\\t', index_col='id')\n",
    "#traindf = pd.read_csv(\"train_set.tsv\", sep='\\t', index_col='id')\n",
    "datadf = pd.read_csv(\"dataset.tsv\", sep='\\t', index_col='id')\n",
    "datadf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1 Δημιουργία WordCloud\n",
    "**Create a WordCloud for the articles of each category**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create our own stopWord list:\n",
    "stopwords = set(STOPWORDS)\n",
    "stopwords.update(['say', 'said', 'saying', 'will', 'many', 'new', 'people', 'now', 'one'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#create wordcloud\n",
    "# select rows where the id contains 'b' (=business) using filter\n",
    "wordcloud_business = WordCloud(\n",
    "    width = 800,\n",
    "    height = 800,\n",
    "    background_color = 'black',\n",
    "    stopwords = stopwords).generate(\" \".join(title+' '+content\n",
    "                                             for title, content in datadf.filter(like='b', axis=0)\n",
    "                                                                   [['title', 'content']].values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "business_image = wordcloud_business.to_image()\n",
    "display(business_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Entertainment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "wordcloud_entertainment = WordCloud(\n",
    "    width = 800,\n",
    "    height = 800,\n",
    "    background_color = 'black',\n",
    "    stopwords = stopwords).generate(str(datadf.filter(like='e', axis=0)[['title', 'content']].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#show it\n",
    "plt.figure(figsize = (8, 8), facecolor = None)\n",
    "plt.imshow(wordcloud_entertainment)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Politics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wordcloud_politics = WordCloud(\n",
    "    width = 800,\n",
    "    height = 800,\n",
    "    background_color = 'black',\n",
    "    stopwords = stopwords).generate(str(datadf.filter(like='p', axis=0)[['title', 'content']].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#show it\n",
    "plt.figure(figsize = (8, 8), facecolor = None)\n",
    "plt.imshow(wordcloud_politics)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wordcloud_sport = WordCloud(\n",
    "    width = 800,\n",
    "    height = 800,\n",
    "    background_color = 'black',\n",
    "    stopwords = stopwords).generate(str(datadf.filter(like='s', axis=0)[['title', 'content']].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#show it\n",
    "plt.figure(figsize = (8, 8), facecolor = None)\n",
    "plt.imshow(wordcloud_sport)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wordcloud_tech = WordCloud(\n",
    "    width = 800,\n",
    "    height = 800,\n",
    "    background_color = 'black',\n",
    "    stopwords = stopwords).generate(str(datadf.filter(like='t', axis=0)[['title', 'content']].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#show it\n",
    "plt.figure(figsize = (8, 8), facecolor = None)\n",
    "plt.imshow(wordcloud_tech)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2 Υλοποίηση Κατηγοριοποίησης (Classification)\n",
    "**Data Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) Cleaning and Pre-processing the data\n",
    "Create a Pandas Series, adding it as a new row into the datadf,\n",
    "by concatenating the title and content column of the datadf <br>\n",
    "Clean up text:<br>\n",
    "- Add a space before performing the sum to not connect words together accidentally\n",
    "- Make all the words lower case to facilitate clean up, using `.lower`\n",
    "- Remove our list of stopwords\n",
    "- Remove punctuation and special characters using `re.sub`\n",
    "- Remove all words containing digits, and any digits using `re.sub`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "datadf['text'] = datadf[['title', 'content']]\\\n",
    "    .apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\\\n",
    "    .apply(lambda item: list(filter(lambda word: word not in stopwords, item.lower().split())))\\\n",
    "    .apply(lambda item: re.sub('[^A-Za-z0-9 ]+', '', ' '.join(item)))\\\n",
    "    .apply(lambda item: re.sub(r'\\w*\\d\\w*', '', item))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bag-of-words\n",
    "Create bag-of-words vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bow_vectorizer = CountVectorizer(max_features=3000, stop_words='english')\n",
    "\n",
    "bow_X = bow_vectorizer.fit_transform(datadf.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>profits</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>profit</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aol</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sales</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>internet</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fewer</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fiat</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>field</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fifth</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zealand</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          counts\n",
       "profits        5\n",
       "profit         5\n",
       "aol            5\n",
       "sales          4\n",
       "internet       4\n",
       "...          ...\n",
       "fewer          0\n",
       "fiat           0\n",
       "field          0\n",
       "fifth          0\n",
       "zealand        0\n",
       "\n",
       "[3000 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(bow_X[0:1].T.todense(), index=bow_vectorizer.get_feature_names(), columns=[\"counts\"])\\\n",
    ".sort_values(by=[\"counts\"],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer= TfidfVectorizer(ngram_range=(1,2), max_features=3000, stop_words='english')\n",
    "\n",
    "tfidf_X = tfidf_vectorizer.fit_transform(datadf.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>profit</th>\n",
       "      <td>0.317210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>profits</th>\n",
       "      <td>0.300447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fourth quarter</th>\n",
       "      <td>0.231995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>internet</th>\n",
       "      <td>0.203663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stake</th>\n",
       "      <td>0.201039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filesharing</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>film festival</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>films</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>finally</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zealand</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   tfidf\n",
       "profit          0.317210\n",
       "profits         0.300447\n",
       "fourth quarter  0.231995\n",
       "internet        0.203663\n",
       "stake           0.201039\n",
       "...                  ...\n",
       "filesharing     0.000000\n",
       "film festival   0.000000\n",
       "films           0.000000\n",
       "finally         0.000000\n",
       "zealand         0.000000\n",
       "\n",
       "[3000 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tfidf_X[0:1].T.todense(), index=tfidf_vectorizer.get_feature_names(), columns=[\"tfidf\"])\\\n",
    ".sort_values(by=[\"tfidf\"],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperate data into train (80%) and test (20%) set <br>\n",
    "Use the stratify parameter to ensure that the split between the different categories is done equally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train_bow, X_test_bow, y_train_bow, y_test_bow = train_test_split(bow_X, datadf.category,\n",
    "                                                                test_size=0.2, stratify=datadf.category)\n",
    "\n",
    "X_train_tfidf, X_test_tfidf, y_train_tfidf, y_test_tfidf = train_test_split(tfidf_X, datadf.category,\n",
    "                                                     test_size=0.2, stratify=datadf.category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### B) Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machines (SVM)\n",
    "*Bag of Words*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#instantiate the model\n",
    "svm_clf = svm.SVC()\n",
    "\n",
    "# train the model on the BoW training set\n",
    "svm_clf.fit(X_train_bow, y_train_bow)\n",
    "# predict the BoW test set\n",
    "y_pred_svm_bow = svm_clf.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold Cross Validation Precision SVM for BoW: 0.9565175917783352\n",
      "10-fold Cross Validation Recall SVM for BoW: 0.954742944556408\n",
      "10-fold Cross Validation F-Measure SVM for BoW: 0.9547562765545926\n",
      "10-fold Cross Validation Accuracy SVM for BoW: 0.9561480352948646\n"
     ]
    }
   ],
   "source": [
    "print(\"10-fold Cross Validation Precision SVM for BoW:\",\n",
    "      np.mean(cross_val_score(svm_clf, X_train_bow, y_train_bow, cv=10, scoring='precision_macro')))\n",
    "print(\"10-fold Cross Validation Recall SVM for BoW:\",\n",
    "      np.mean(cross_val_score(svm_clf, X_train_bow, y_train_bow, cv=10, scoring='recall_macro')))\n",
    "print(\"10-fold Cross Validation F-Measure SVM for BoW:\",\n",
    "     np.mean(cross_val_score(svm_clf, X_train_bow, y_train_bow, cv=10, scoring='f1_macro')))\n",
    "print(\"10-fold Cross Validation Accuracy SVM for BoW:\",\n",
    "      np.mean(cross_val_score(svm_clf, X_train_bow, y_train_bow, cv=10, scoring='accuracy')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TF/IDF*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model on the TF/IDF training set (previous weights and variables are reset)\n",
    "svm_clf.fit(X_train_tfidf, y_train_tfidf)\n",
    "# predict the TF/IDF test set\n",
    "y_pred_svm_tfidf = svm_clf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold Cross Validation Precision SVM for TF/IDF: 0.9787102885785025\n",
      "10-fold Cross Validation Recall SVM for TF/IDF: 0.9772926501442434\n",
      "10-fold Cross Validation F-Measure SVM for TF/IDF: 0.9776337232521144\n",
      "10-fold Cross Validation Accuracy SVM for TF/IDF: 0.9780803656446391\n"
     ]
    }
   ],
   "source": [
    "print(\"10-fold Cross Validation Precision SVM for TF/IDF:\",\n",
    "      np.mean(cross_val_score(svm_clf, X_train_tfidf, y_train_tfidf, cv=10, scoring='precision_macro')))\n",
    "print(\"10-fold Cross Validation Recall SVM for TF/IDF:\",\n",
    "      np.mean(cross_val_score(svm_clf, X_train_tfidf, y_train_tfidf, cv=10, scoring='recall_macro')))\n",
    "print(\"10-fold Cross Validation F-Measure SVM for TF/IDF:\",\n",
    "     np.mean(cross_val_score(svm_clf, X_train_tfidf, y_train_tfidf, cv=10, scoring='f1_macro')))\n",
    "print(\"10-fold Cross Validation Accuracy SVM for TF/IDF:\",\n",
    "      np.mean(cross_val_score(svm_clf, X_train_tfidf, y_train_tfidf, cv=10, scoring='accuracy')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Train the model on the BoW training set\n",
    "rf.fit(X_train_bow, y_train_bow)\n",
    "# predict the BoW test set\n",
    "y_pred_rf_bow = rf.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold Cross Validation Precision RF for BoW: 0.9584077891919411\n",
      "10-fold Cross Validation Recall RF for BoW: 0.9512703472920532\n",
      "10-fold Cross Validation F-Measure RF for BoW: 0.9564563907493066\n",
      "10-fold Cross Validation Accuracy RF for BoW: 0.9572875007934997\n"
     ]
    }
   ],
   "source": [
    "print(\"10-fold Cross Validation Precision RF for BoW:\",\n",
    "      np.mean(cross_val_score(rf, X_train_bow, y_train_bow, cv=10, scoring='precision_macro')))\n",
    "print(\"10-fold Cross Validation Recall RF for BoW:\",\n",
    "      np.mean(cross_val_score(rf, X_train_bow, y_train_bow, cv=10, scoring='recall_macro')))\n",
    "print(\"10-fold Cross Validation F-Measure RF for BoW:\",\n",
    "     np.mean(cross_val_score(rf, X_train_bow, y_train_bow, cv=10, scoring='f1_macro')))\n",
    "print(\"10-fold Cross Validation Accuracy RF for BoW:\",\n",
    "      np.mean(cross_val_score(rf, X_train_bow, y_train_bow, cv=10, scoring='accuracy')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model on the TF/IDF training set (previous weights and variables are reset)\n",
    "rf.fit(X_train_tfidf, y_train_tfidf)\n",
    "# predict the TF/IDF test set\n",
    "y_pred_rf_tfidf = rf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold Cross Validation Precision RF for TF/IDF: 0.9559219604156663\n",
      "10-fold Cross Validation Recall RF for TF/IDF: 0.9537794184264078\n",
      "10-fold Cross Validation F-Measure RF for TF/IDF: 0.9556791794861443\n",
      "10-fold Cross Validation Accuracy RF for TF/IDF: 0.9561639052878818\n"
     ]
    }
   ],
   "source": [
    "print(\"10-fold Cross Validation Precision RF for TF/IDF:\",\n",
    "      np.mean(cross_val_score(rf, X_train_tfidf, y_train_tfidf, cv=10, scoring='precision_macro')))\n",
    "print(\"10-fold Cross Validation Recall RF for TF/IDF:\",\n",
    "      np.mean(cross_val_score(rf, X_train_tfidf, y_train_tfidf, cv=10, scoring='recall_macro')))\n",
    "print(\"10-fold Cross Validation F-Measure RF for TF/IDF:\",\n",
    "     np.mean(cross_val_score(rf, X_train_tfidf, y_train_tfidf, cv=10, scoring='f1_macro')))\n",
    "print(\"10-fold Cross Validation Accuracy RF for TF/IDF:\",\n",
    "      np.mean(cross_val_score(rf, X_train_tfidf, y_train_tfidf, cv=10, scoring='accuracy')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "nb = GaussianNB()\n",
    "\n",
    "# Train the model on the BoW training set\n",
    "nb.fit(X_train_bow.toarray(), y_train_bow)\n",
    "# predict the BoW test set\n",
    "y_pred_nb_bow = nb.predict(X_test_bow.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold Cross Validation Precision NB for BoW: 0.9117331574099212\n",
      "10-fold Cross Validation Recall NB for BoW: 0.907036509632821\n",
      "10-fold Cross Validation F-Measure NB for BoW: 0.9062662308179504\n",
      "10-fold Cross Validation Accuracy NB for BoW: 0.9089601980575128\n"
     ]
    }
   ],
   "source": [
    "print(\"10-fold Cross Validation Precision NB for BoW:\",\n",
    "      np.mean(cross_val_score(nb, X_train_bow.toarray(), y_train_bow, cv=10, scoring='precision_macro')))\n",
    "print(\"10-fold Cross Validation Recall NB for BoW:\",\n",
    "      np.mean(cross_val_score(nb, X_train_bow.toarray(), y_train_bow, cv=10, scoring='recall_macro')))\n",
    "print(\"10-fold Cross Validation F-Measure NB for BoW:\",\n",
    "     np.mean(cross_val_score(nb, X_train_bow.toarray(), y_train_bow, cv=10, scoring='f1_macro')))\n",
    "print(\"10-fold Cross Validation Accuracy NB for BoW:\",\n",
    "      np.mean(cross_val_score(nb, X_train_bow.toarray(), y_train_bow, cv=10, scoring='accuracy')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on the TF/IDF training set (previous weights and variables are reset)\n",
    "nb.fit(X_train_tfidf.toarray(), y_train_tfidf)\n",
    "# predict the TF/IDF test set\n",
    "y_pred_nb_tfidf = nb.predict(X_test_tfidf.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold Cross Validation Precision NB for TF/IDF: 0.9191979154110038\n",
      "10-fold Cross Validation Recall NB for TF/IDF: 0.9141024978226753\n",
      "10-fold Cross Validation F-Measure NB for TF/IDF: 0.9137376485180313\n",
      "10-fold Cross Validation Accuracy NB for TF/IDF: 0.9168158446010283\n"
     ]
    }
   ],
   "source": [
    "print(\"10-fold Cross Validation Precision NB for TF/IDF:\",\n",
    "      np.mean(cross_val_score(nb, X_train_tfidf.toarray(), y_train_tfidf, cv=10, scoring='precision_macro')))\n",
    "print(\"10-fold Cross Validation Recall NB for TF/IDF:\",\n",
    "      np.mean(cross_val_score(nb, X_train_tfidf.toarray(), y_train_tfidf, cv=10, scoring='recall_macro')))\n",
    "print(\"10-fold Cross Validation F-Measure NB for TF/IDF:\",\n",
    "     np.mean(cross_val_score(nb, X_train_tfidf.toarray(), y_train_tfidf, cv=10, scoring='f1_macro')))\n",
    "print(\"10-fold Cross Validation Accuracy NB for TF/IDF:\",\n",
    "      np.mean(cross_val_score(nb, X_train_tfidf.toarray(), y_train_tfidf, cv=10, scoring='accuracy')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-Nearest Neighbor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the majority voting function. It returns the value that appears more often in List. If two values have the same number of appearances in the list, it returns the first element of the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mode, StatisticsError\n",
    "\n",
    "def maj_voting(List): \n",
    "    try:\n",
    "        return mode(List)\n",
    "    except StatisticsError:\n",
    "        return List[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be creating our own KNN estimator which will be scikit-learn-compatible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import euclidean_distances\n",
    "from sklearn.neighbors import KDTree\n",
    "\n",
    "class MyKNNClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, n_neighbors=5, leaf_size=40):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        # leaf size for the KDTree\n",
    "        self.leaf_size = leaf_size\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Check that X and y have correct shape\n",
    "        X, y = check_X_y(X, y)\n",
    "        # Store the classes seen during fit\n",
    "        self.classes_ = unique_labels(y)\n",
    "\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "        # Create the KDTree\n",
    "        self._tree = KDTree(X, self.leaf_size)\n",
    "        \n",
    "        # Return the classifier\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Check is fit had been called\n",
    "        check_is_fitted(self)\n",
    "        \n",
    "        # Input validation\n",
    "        X = check_array(X)\n",
    "\n",
    "        #closest = np.argmin(euclidean_distances(X, self.X_), axis=1)\n",
    "        closest_dist, closest_indices = self._tree.query(X, k=self.n_neighbors)\n",
    "        return np.array(list(map(maj_voting, self.y_[closest_indices])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check whether estimator adheres to the scikit-learn interface and standards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.estimator_checks import check_estimator\n",
    "check_estimator(MyKNNClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use our custom classifier for our dataset (BoW and TF/IDF):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "myclf = MyKNNClassifier(n_neighbors=2)\n",
    "\n",
    "# Train the model on the BoW training set\n",
    "myclf.fit(X_train_bow.toarray(), y_train_bow)\n",
    "# predict the BoW test set\n",
    "y_pred_test_bow = myclf.predict(X_test_bow.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of My KNN for BoW: 0.8224719101123595\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy of My KNN for BoW:\",metrics.accuracy_score(y_test_bow, y_pred_test_bow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scores of Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision SVM for BoW: [0.98947368 0.98701299 0.96428571 0.98019802 0.875     ]\n",
      "Precision SVM for TF/IDF: [0.98969072 1.         0.95402299 1.         0.95238095]\n",
      "Precision RF for BoW: [0.97       0.97402597 0.97590361 0.95327103 0.94871795]\n",
      "Precision RF for TF/IDF: [0.93333333 0.97333333 0.97530864 0.97142857 0.93670886]\n",
      "Precision NB for BoW: [0.94565217 0.92857143 0.89655172 0.98989899 0.79381443]\n",
      "Precision NB for TF/IDF: [0.91208791 0.92537313 0.87209302 1.         0.74509804]\n",
      "\n",
      "Recall SVM for BoW: [0.92156863 0.98701299 0.96428571 0.97058824 0.9625    ]\n",
      "Recall SVM for TF/IDF: [0.94117647 0.97402597 0.98809524 1.         1.        ]\n",
      "Recall RF for BoW: [0.95098039 0.97402597 0.96428571 1.         0.925     ]\n",
      "Recall RF for TF/IDF: [0.96078431 0.94805195 0.94047619 1.         0.925     ]\n",
      "Recall NB for BoW: [0.85294118 0.84415584 0.92857143 0.96078431 0.9625    ]\n",
      "Recall NB for TF/IDF: [0.81372549 0.80519481 0.89285714 0.97058824 0.95      ]\n",
      "\n",
      "F-Measure SVM for BoW: [0.95431472 0.98701299 0.96428571 0.97536946 0.91666667]\n",
      "F-Measure SVM for TF/IDF: [0.96482412 0.98684211 0.97076023 1.         0.97560976]\n",
      "F-Measure RF for BoW: [0.96039604 0.97402597 0.97005988 0.97607656 0.93670886]\n",
      "F-Measure RF for TF/IDF: [0.9468599  0.96052632 0.95757576 0.98550725 0.93081761]\n",
      "F-Measure NB for BoW: [0.89690722 0.88435374 0.9122807  0.97512438 0.8700565 ]\n",
      "F-Measure NB for TF/IDF: [0.86010363 0.86111111 0.88235294 0.98507463 0.83516484]\n",
      "\n",
      "Accuracy SVM for BoW: 0.9595505617977528\n",
      "Accuracy SVM for TF/IDF: 0.9797752808988764\n",
      "Accuracy RF for BoW: 0.9640449438202248\n",
      "Accuracy RF for TF/IDF: 0.9573033707865168\n",
      "Accuracy NB for BoW: 0.9101123595505618\n",
      "Accuracy NB for TF/IDF: 0.8876404494382022\n"
     ]
    }
   ],
   "source": [
    "#Model Precision: what percentage was classified correctly?\n",
    "print(\"Precision SVM for BoW:\",metrics.precision_score(y_test_bow, y_pred_svm_bow, average=None))\n",
    "print(\"Precision SVM for TF/IDF:\",metrics.precision_score(y_test_tfidf, y_pred_svm_tfidf, average=None))\n",
    "print(\"Precision RF for BoW:\",metrics.precision_score(y_test_bow, y_pred_rf_bow, average=None))\n",
    "print(\"Precision RF for TF/IDF:\",metrics.precision_score(y_test_tfidf, y_pred_rf_tfidf, average=None))\n",
    "print(\"Precision NB for BoW:\",metrics.precision_score(y_test_bow, y_pred_nb_bow, average=None))\n",
    "print(\"Precision NB for TF/IDF:\",metrics.precision_score(y_test_tfidf, y_pred_nb_tfidf, average=None))\n",
    "\n",
    "print()\n",
    "# Model Recall\n",
    "print(\"Recall SVM for BoW:\",metrics.recall_score(y_test_bow, y_pred_svm_bow, average=None))\n",
    "print(\"Recall SVM for TF/IDF:\",metrics.recall_score(y_test_tfidf, y_pred_svm_tfidf, average=None))\n",
    "print(\"Recall RF for BoW:\",metrics.recall_score(y_test_bow, y_pred_rf_bow, average=None))\n",
    "print(\"Recall RF for TF/IDF:\",metrics.recall_score(y_test_tfidf, y_pred_rf_tfidf, average=None))\n",
    "print(\"Recall NB for BoW:\",metrics.recall_score(y_test_bow, y_pred_nb_bow, average=None))\n",
    "print(\"Recall NB for TF/IDF:\",metrics.recall_score(y_test_tfidf, y_pred_nb_tfidf, average=None))\n",
    "\n",
    "print()\n",
    "# F-Measure\n",
    "print(\"F-Measure SVM for BoW:\", metrics.f1_score(y_test_bow, y_pred_svm_bow, average=None))\n",
    "print(\"F-Measure SVM for TF/IDF:\", metrics.f1_score(y_test_tfidf, y_pred_svm_tfidf, average=None))\n",
    "print(\"F-Measure RF for BoW:\", metrics.f1_score(y_test_bow, y_pred_rf_bow, average=None))\n",
    "print(\"F-Measure RF for TF/IDF:\", metrics.f1_score(y_test_tfidf, y_pred_rf_tfidf, average=None))\n",
    "print(\"F-Measure NB for BoW:\", metrics.f1_score(y_test_bow, y_pred_nb_bow, average=None))\n",
    "print(\"F-Measure NB for TF/IDF:\", metrics.f1_score(y_test_tfidf, y_pred_nb_tfidf, average=None))\n",
    "\n",
    "print()\n",
    "# compare actual response values (y_test) with predicted response values (y_pred)\n",
    "print(\"Accuracy SVM for BoW:\",metrics.accuracy_score(y_test_bow, y_pred_svm_bow))\n",
    "print(\"Accuracy SVM for TF/IDF:\",metrics.accuracy_score(y_test_tfidf, y_pred_svm_tfidf))\n",
    "print(\"Accuracy RF for BoW:\",metrics.accuracy_score(y_test_bow, y_pred_rf_bow))\n",
    "print(\"Accuracy RF for TF/IDF:\",metrics.accuracy_score(y_test_tfidf, y_pred_rf_tfidf))\n",
    "print(\"Accuracy NB for BoW:\",metrics.accuracy_score(y_test_bow, y_pred_nb_bow))\n",
    "print(\"Accuracy NB for TF/IDF:\",metrics.accuracy_score(y_test_tfidf, y_pred_nb_tfidf))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
