{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Εργασία 2 (Τεχνικές Εξόρυξης Δεδομένων)\n",
    "## Data Mining: Assignment 2\n",
    "***\n",
    "### Μαρία Φριτζελά 1115201400218\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import csv\n",
    "import re\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "from IPython.core.display import display\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Κατηγοριοποίηση δεδομένων κειμένου από ειδησιογραφικά άρθρα 5 κατηγοριών:</br>\n",
    "Classifying text data from articles of 5 different categories:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "categories = ['business', 'entertainment', 'politics', 'sport', 'tech']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Get names of files for testing and training\n",
    "Data set consists of 2225 documents from a news website\n",
    "corresponding to stories in five topical areas from 2004-2005.</br>\n",
    "</br>\n",
    "80% of data points (files) will be used for training, the remaining 20% will be used for testing.</br>\n",
    "We will be collecting the files names as elements in two lists (one for each purpose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "files_path = 'fulltext/data/'\n",
    "train_files = []    # list of files names that will be used for training\n",
    "test_files = []     # list of files names that will be used for testing\n",
    "\n",
    "for category in categories:\n",
    "    # get all txt files names from current category\n",
    "    files = glob.glob(files_path+category+'/*.txt')\n",
    "    # sort them alphabetically\n",
    "    files.sort()\n",
    "    # separate list so that first 80% will be copied into the train_files list\n",
    "    sep_index = round(len(files) * 0.8)\n",
    "    train_files.extend(files[:sep_index])\n",
    "    test_files.extend(files[sep_index:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Total files: 2225\")\n",
    "print(\"# of train files: \"+str(len(train_files)))\n",
    "print(\"# of test files: \"+str(len(test_files)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Create file train_set.tsv\n",
    "Columns: id, title, content, category <br>\n",
    "_The id is the name of the text file with the first letter of the category prepended (ex. \"b001\")_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('train_set.tsv', 'wt') as out_file:\n",
    "    tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "    # write header row\n",
    "    tsv_writer.writerow(['id', 'title', 'content', 'category'])\n",
    "    # write rows for all other files\n",
    "    for file_path in train_files:\n",
    "        with open(file_path) as f:\n",
    "            # read all lines of file split them in a list removing '\\n'\n",
    "            # iterate through elements in list removing empty ones (empty strings are False)\n",
    "            try:\n",
    "                content = [line for line in f.read().splitlines() if line.strip()]\n",
    "                # unpack the information we need from the file path\n",
    "                _, _, cat, name, _ = file_path.replace('.', '/').split('/')\n",
    "                # Write row\n",
    "                tsv_writer.writerow([cat[0]+name,\n",
    "                                 content.pop(0),\n",
    "                                 \" \".join(content),\n",
    "                                 cat])\n",
    "            except UnicodeDecodeError:\n",
    "                print(\"UnicodeDecodeError for file: \"+file_path+\". File skipped\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Create file test_set.tsv\n",
    "Columns: id, title, content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('test_set.tsv', 'wt') as out_file:\n",
    "    tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "    # write header row\n",
    "    tsv_writer.writerow(['id', 'title', 'content'])\n",
    "    # write rows for all other files\n",
    "    for file_path in test_files:\n",
    "        with open(file_path) as f:\n",
    "            # read all lines of file split them in a list removing '\\n'\n",
    "            # iterate through elements in list removing empty ones (empty strings are False)\n",
    "            try:\n",
    "                content = [line for line in f.read().splitlines() if line.strip()]\n",
    "                # unpack the information we need from the file path\n",
    "                _, _, cat, name, _ = file_path.replace('.', '/').split('/')\n",
    "                # Write row\n",
    "                tsv_writer.writerow([cat[0]+name,\n",
    "                                 content.pop(0),\n",
    "                                 \" \".join(content)])\n",
    "            except UnicodeDecodeError:\n",
    "                print(\"UnicodeDecodeError for file: \"+file_path+\". File skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Create a file with the full dataset: dataset.tsv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnicodeDecodeError for file: fulltext/data/sport/199.txt. File skipped\n"
     ]
    }
   ],
   "source": [
    "with open('dataset.tsv', 'wt') as out_file:\n",
    "    tsv_writer = csv.writer(out_file, delimiter='\\t')\n",
    "    # write header row\n",
    "    tsv_writer.writerow(['id', 'title', 'content', 'category'])\n",
    "    # write rows for all other files\n",
    "    for file_path in chain(train_files, test_files):\n",
    "        with open(file_path) as f:\n",
    "            # read all lines of file split them in a list removing '\\n'\n",
    "            # iterate through elements in list removing empty ones (empty strings are False)\n",
    "            try:\n",
    "                content = [line for line in f.read().splitlines() if line.strip()]\n",
    "                # unpack the information we need from the file path\n",
    "                _, _, cat, name, _ = file_path.replace('.', '/').split('/')\n",
    "                # Write row\n",
    "                tsv_writer.writerow([cat[0]+name,\n",
    "                                 content.pop(0),\n",
    "                                 \" \".join(content),\n",
    "                                 cat])\n",
    "            except UnicodeDecodeError:\n",
    "                print(\"UnicodeDecodeError for file: \"+file_path+\". File skipped\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Create a DataFrame for the data_set (id column as the index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>b001</th>\n",
       "      <td>Ad sales boost Time Warner profit</td>\n",
       "      <td>Quarterly profits at US media giant TimeWarner...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b002</th>\n",
       "      <td>Dollar gains on Greenspan speech</td>\n",
       "      <td>The dollar has hit its highest level against t...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b003</th>\n",
       "      <td>Yukos unit buyer faces loan claim</td>\n",
       "      <td>The owners of embattled Russian oil giant Yuko...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b004</th>\n",
       "      <td>High fuel prices hit BA's profits</td>\n",
       "      <td>British Airways has blamed high fuel prices fo...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b005</th>\n",
       "      <td>Pernod takeover talk lifts Domecq</td>\n",
       "      <td>Shares in UK drinks and food firm Allied Domec...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t397</th>\n",
       "      <td>BT program to beat dialler scams</td>\n",
       "      <td>BT is introducing two initiatives to help beat...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t398</th>\n",
       "      <td>Spam e-mails tempt net shoppers</td>\n",
       "      <td>Computer users across the world continue to ig...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t399</th>\n",
       "      <td>Be careful how you code</td>\n",
       "      <td>A new European directive could put software wr...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t400</th>\n",
       "      <td>US cyber security chief resigns</td>\n",
       "      <td>The man making sure US computer networks are s...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t401</th>\n",
       "      <td>Losing yourself in online gaming</td>\n",
       "      <td>Online role playing games are time-consuming, ...</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2224 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  title  \\\n",
       "id                                        \n",
       "b001  Ad sales boost Time Warner profit   \n",
       "b002   Dollar gains on Greenspan speech   \n",
       "b003  Yukos unit buyer faces loan claim   \n",
       "b004  High fuel prices hit BA's profits   \n",
       "b005  Pernod takeover talk lifts Domecq   \n",
       "...                                 ...   \n",
       "t397   BT program to beat dialler scams   \n",
       "t398    Spam e-mails tempt net shoppers   \n",
       "t399            Be careful how you code   \n",
       "t400    US cyber security chief resigns   \n",
       "t401   Losing yourself in online gaming   \n",
       "\n",
       "                                                content  category  \n",
       "id                                                                 \n",
       "b001  Quarterly profits at US media giant TimeWarner...  business  \n",
       "b002  The dollar has hit its highest level against t...  business  \n",
       "b003  The owners of embattled Russian oil giant Yuko...  business  \n",
       "b004  British Airways has blamed high fuel prices fo...  business  \n",
       "b005  Shares in UK drinks and food firm Allied Domec...  business  \n",
       "...                                                 ...       ...  \n",
       "t397  BT is introducing two initiatives to help beat...      tech  \n",
       "t398  Computer users across the world continue to ig...      tech  \n",
       "t399  A new European directive could put software wr...      tech  \n",
       "t400  The man making sure US computer networks are s...      tech  \n",
       "t401  Online role playing games are time-consuming, ...      tech  \n",
       "\n",
       "[2224 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#testdf = pd.read_csv(\"test_set.tsv\", sep='\\t', index_col='id')\n",
    "#traindf = pd.read_csv(\"train_set.tsv\", sep='\\t', index_col='id')\n",
    "datadf = pd.read_csv(\"dataset.tsv\", sep='\\t', index_col='id')\n",
    "datadf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1 Δημιουργία WordCloud\n",
    "**Create a WordCloud for the articles of each category**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Create our own stopWord list:\n",
    "stopwords = set(STOPWORDS)\n",
    "stopwords.update(['say', 'said', 'saying', 'will', 'many', 'new', 'people', 'now', 'one'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#create wordcloud\n",
    "# select rows where the id contains 'b' (=business) using filter\n",
    "wordcloud_business = WordCloud(\n",
    "    width = 800,\n",
    "    height = 800,\n",
    "    background_color = 'black',\n",
    "    stopwords = stopwords).generate(\" \".join(title+' '+content\n",
    "                                             for title, content in datadf.filter(like='b', axis=0)\n",
    "                                                                   [['title', 'content']].values.tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "business_image = wordcloud_business.to_image()\n",
    "display(business_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Entertainment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud_entertainment = WordCloud(\n",
    "    width = 800,\n",
    "    height = 800,\n",
    "    background_color = 'black',\n",
    "    stopwords = stopwords).generate(str(datadf.filter(like='e', axis=0)[['title', 'content']].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#show it\n",
    "plt.figure(figsize = (8, 8), facecolor = None)\n",
    "plt.imshow(wordcloud_entertainment)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Politics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wordcloud_politics = WordCloud(\n",
    "    width = 800,\n",
    "    height = 800,\n",
    "    background_color = 'black',\n",
    "    stopwords = stopwords).generate(str(datadf.filter(like='p', axis=0)[['title', 'content']].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#show it\n",
    "plt.figure(figsize = (8, 8), facecolor = None)\n",
    "plt.imshow(wordcloud_politics)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wordcloud_sport = WordCloud(\n",
    "    width = 800,\n",
    "    height = 800,\n",
    "    background_color = 'black',\n",
    "    stopwords = stopwords).generate(str(datadf.filter(like='s', axis=0)[['title', 'content']].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#show it\n",
    "plt.figure(figsize = (8, 8), facecolor = None)\n",
    "plt.imshow(wordcloud_sport)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wordcloud_tech = WordCloud(\n",
    "    width = 800,\n",
    "    height = 800,\n",
    "    background_color = 'black',\n",
    "    stopwords = stopwords).generate(str(datadf.filter(like='t', axis=0)[['title', 'content']].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#show it\n",
    "plt.figure(figsize = (8, 8), facecolor = None)\n",
    "plt.imshow(wordcloud_tech)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2 Υλοποίηση Κατηγοριοποίησης (Classification)\n",
    "**Data Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### A) Cleaning and Pre-processing the data\n",
    "Create a Pandas Series by concatenating the title and content column of the datadf <br>\n",
    "Clean up text:<br>\n",
    "- Add a space before performing the sum to not connect words together accidentally\n",
    "- Make all the words lower case to facilitate clean up, using `.lower`\n",
    "- Remove our list of stopwords\n",
    "- Remove punctuation and special characters using `re.sub`\n",
    "- Remove all words containing digits, and any digits using `re.sub`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "datadf['text'] = datadf[['title', 'content']]\\\n",
    "    .apply(lambda row: ' '.join(row.values.astype(str)), axis=1)\\\n",
    "    .apply(lambda item: list(filter(lambda word: word not in stopwords, item.lower().split())))\\\n",
    "    .apply(lambda item: re.sub('[^A-Za-z0-9 ]+', '', ' '.join(item)))\\\n",
    "    .apply(lambda item: re.sub(r'\\w*\\d\\w*', '', item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperate data into train (80%) and test (20%) set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(datadf.text, datadf.category, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Bag-of-words\n",
    "Create bag-of-words vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bow_vectorizer = CountVectorizer(max_features=3000, stop_words='english')\n",
    "\n",
    "bow_X = bow_vectorizer.fit_transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>iraq</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrs</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>care</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>war</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>international</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fees</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fell</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fellow</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>felt</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zealand</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               counts\n",
       "iraq                6\n",
       "mrs                 3\n",
       "care                3\n",
       "war                 2\n",
       "international       2\n",
       "...               ...\n",
       "fees                0\n",
       "fell                0\n",
       "fellow              0\n",
       "felt                0\n",
       "zealand             0\n",
       "\n",
       "[3000 rows x 1 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(bow_X[0:1].T.todense(), index=bow_vectorizer.get_feature_names(), columns=[\"counts\"])\\\n",
    ".sort_values(by=[\"counts\"],ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tfidf_vectorizer= TfidfVectorizer(ngram_range=(1,2), max_features=3000, stop_words='english')\n",
    "\n",
    "tfidf = tfidf_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>iraq</th>\n",
       "      <td>0.532979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrs</th>\n",
       "      <td>0.357154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>care</th>\n",
       "      <td>0.274610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>operations</th>\n",
       "      <td>0.184546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aid</th>\n",
       "      <td>0.177660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>file</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filed</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>files</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>filesharing</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zealand</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                tfidf\n",
       "iraq         0.532979\n",
       "mrs          0.357154\n",
       "care         0.274610\n",
       "operations   0.184546\n",
       "aid          0.177660\n",
       "...               ...\n",
       "file         0.000000\n",
       "filed        0.000000\n",
       "files        0.000000\n",
       "filesharing  0.000000\n",
       "zealand      0.000000\n",
       "\n",
       "[3000 rows x 1 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(tfidf[0:1].T.todense(), index=tfidf_vectorizer.get_feature_names(), columns=[\"tfidf\"])\\\n",
    ".sort_values(by=[\"tfidf\"],ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### B) Classification\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}